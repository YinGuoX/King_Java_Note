# 面试问答

- 主要参考自本人面试经历

# 1. 2021.12.22-字节电商一面凉经

- **总结：认真理解别人说话！自己说话要条理清晰！**
- 自我介绍
- 实习时间
- 介绍一个自己做的觉得很牛的项目
  - 棋盘转换项目：
    - 实现的功能：将棋盘图片转为棋盘矩阵
    - 实现的目的：实现线下棋盘转换到线上，提供智能对弈功能，AI研究，提示下一步棋的下法、或者判断输赢
    - 实现的方法：传统的数字图像处理，采用opencv
  - 图像处理
  - 深度学习-神经网络
    - 神经元：线性模型+激活函数
      - 线性模型：数据拟合值和真实值的关系
      - 激活函数：加入非线性映射，进行数学映射
    - 神经网络：定义一个函数集合，通过训练一个神经网络就是在这个函数集合中找到一个唯一的函数，这个函数代表了训练样本的共性特征，通过共性特征就可以进行分类
  - 调参
  - 什么时候可以使用神经网络？什么时候使用传统方法？
    - 如果有很多数据，并且不确定这些数据的结构，如：图像、音频等非结构化数据，那么使用深度学习比较合适
      - 就比如去年shoppe在kaggle开放的根据商品名字和图片进行分类的竞赛，使用的就是CV+NLP
        - 是通过图片来判断这两个商品是否为相同商品，也就是**图像匹配**的问题或者说是**分类**问题。
        - 主要三种思想：
          - 从文本embedding生成文本匹配，从图像embedding生成图像匹配，然后对文本匹配和图像匹配进行union；
          - 将文本embedding和图像emebdding进行concat->生成组合的匹配；
          - 对组合匹配、文本匹配和图像匹配进行union；
    - 如果数据属于结构化数据、或者是说不同类别都有不同的固定的特征，就用传统的方法：比如决策树、贝叶斯概率啥的
- Java提供的锁机制？什么时候释放锁？什么时候加锁？
  - 并发编程的三个概念？
    - 原子性：多个操作要不同时成功，要不同时失败
    - 可见性：当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。
    - 有序性：即程序执行的顺序按照代码的先后顺序执行
      - 指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。
      - 要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。
  - JMM：
    - JMM一种协议，用来屏蔽各个硬件平台和操作系统的访问差异，以实现Java程序在各个平台都可以达到一致的内存访问效果
    - 主要定义了程序中的变量的访问规则，也可以说是数据访问规则、程序的执行次序，但是为了获得更好的执行性能，JMM并没有限制执行引擎使用指令重排或者高速缓存来提升指令执行速度，因此也会存在缓存一致性问题和指令排序问题
      - 解决缓存一致性问题：
        - 通过在总线上加lock锁的方式：因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。
        - 通过缓存一致性协议：Intel  的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。
    - 原子性：
      - Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。
    - 可见性：
      - 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去主内存中读取新值。
      - 通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。
    - 有序性：
      - Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。
      - 在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。
      - Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before  原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。
  - synchronized：
    - 有什么用？
      - 用来解决多个线程之间访问资源的同步性，保证被它修饰的方法或者代码块在任意时刻只有一个线程执行，互斥条件！
      - JDK1.6之前属于重量级锁：因为使用jvm monitor依赖底层操作系统的Mutex Lock(互斥量)来实现，Java的线程是映射到操作系统的原生的线程之上，需要操作系统的支持，需要内核态和用户态的转换，比较耗费资源
      - jdk1.6之后，在jvm层面进行了优化，采用了自旋锁、轻量级锁、锁消除、锁粗化、偏向级锁等技术来减少锁的开销
    - 怎么用？
      - 修饰方法：如果对方法进行加锁，那么在进入该实例对象的方法时，需要先获得当前实例对象的锁
        - 字节码指令：使用ACC_SYNCHRONIZED标识
      - 修饰静态方法：给当前类加锁，作用于类的所有对象实例，进入同步代码前，需要获取当前class的锁
      - 修饰代码块：可以给指定的对象或者类进行加锁，进入代码块之前需要获得指定的锁
        - 字节码指令：使用monitorenter和monitorexit来指定同步代码的开始和结束位置
  - ReentrantLock：
    - 是Java.util.concurrent包中的锁，可以显式的加锁和解锁
    - 优点：
      - 使锁更加公平
      - 可以使线程在等待锁的时候响应中断
      - 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时机
      - 可以在不同的范围内，以不同的顺序获取和释放锁
  - synchronized和reentrantlock的异同？
    - 相同点：
      - 都实现了多线程同步和内存可见性语义
      - 都是可重入锁
    - 不同点：
      - 同步实现机制不同：
        - synchronized通过java对象头锁标记和Monitor对象实现同步
        - ReentrantLock通过CAS、AQS和LockSupport(用于阻塞和解除阻塞)实现同步
      - 可见性实现机制不同：
        - synchronized依赖JVM内存模型来保证共享变量的多线程内存可见性
        - reentrantLock通过AQS的volatile state保证包含共享变量的多线程内存可见性
      - 使用方式不同：
        - synchronized可以修饰方法(锁对象)、静态方法(锁类对象)、代码块(显式指定锁对象)
        - ReentrantLock显式调用tryLock和lock方法，需要在finally块中释放锁
      - 功能丰富程度不同：
        - synchronized不可设置等待时机，不可被中断
        - ReentrantLock可以提供有限时间等候锁，可中断锁，condition等
      - 锁类型不同：
        - synchronized只支持非公平锁
        - ReentrantLock提供非公平锁和公平锁
  - volatile？
    - 和synchronized是互补的，
    - 有什么用？
      - volatile是线程同步的轻量级实现，只能用于变量，是一种弱同步机制，当读取volatile类型的变量时，总是返回最新写入的值
    - 何时使用？
      - 适用于读多写少的环境，可以用来做状态标志
      - 对变量的写操作不依赖于当前值
    - 可见性？
      - 当多个线程访问同一个变量时，如果有一个线程修改了该变量，其他线程都可以读取到该变量的最新值
      - JVM可以保证每次读取变量都是从主内存中读取，而不是工作内存（JMM内存模型！）
    - 不能保证原子性？
      - 原子性：事务！多个操作要不同时执行，要不不执行
      - inc++：自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。
        - 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；
        - 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。
        - 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。
        - 那么两个线程分别进行了一次自增操作后，inc只增加了1。
        - 前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，**线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。**
        - 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。
    - 指令重排？内存屏障？
      - 为什么要指令重排：优化代码运行效率、局部性原理、矩阵乘法举例
      - 如何实现禁止指令重排？
        - 内存屏障：告诉编译器，不允许你指令重排序
        - 禁止指令重排有什么用？
          - 可以确保一定程度的有序性
    - volatile如何实现禁止指令重排？
      - 观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”
      - lock前缀指令实际上相当于一个内存屏障（也成内存栅栏）
        - 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
        - 它会强制将对缓存的修改操作立即写入主存；
        - 如果是写操作，它会导致其他CPU中对应的缓存行无效。
  - 单例模式？
    - 饿汉、懒汉、DCL、
    - 枚举为什么可以防止反射破解？
      - 反编译后：发现枚举类是被abstract修饰，压根就不能被反射实例化
      - 如何保证线程安全：使用了static代码块实现类的初始化
- 死锁发生的条件？怎么破解死锁？
  - 什么是死锁？
    - 多个线程都在等待某个资源被释放，导致都被阻塞了，比如线程A持有资源2，但是需要申请资源1才能继续运行，而线程B已经持有资源1，但是希望获取资源2，此时这两个线程就需要相互等待对方的资源释放，从而导致进入死锁状态
  - 死锁产生的条件：
    - 从时间上来看的话，每个共享资源在任意时刻只能够被一个线程占有=》**互斥条件**
    - 一个线程在获得一个资源后，可以继续请求新的资源，并且已经获得的资源不会被释放掉=》**请求与保持条件（占有等待）**
    - 一个线程已经获得的资源不会别其他线程强行抢占，只会自己释放=》**不剥夺条件（不可抢占）**
    - 若干个线程之间会形成一种首尾相接的循环等待资源关系，每个进程都在等待下一个进程所占有的资源=》**循环等待条件（环路等待）**
    - 一句话：从时间角度，从资源角度，从线程角度，最终导致循环等待条件！
      - 每个资源在任意时刻只能被一个线程占有，一个线程在获得一个资源后，可以继续请求其他资源，已经获得的资源不会被其他线程强行剥夺，最终若干个线程形成一种循环等待资源的关系，每个进程都在等待下一个进程所占有的资源，最终导致死锁问题的产生
  - 如何解决死锁问题？
    - 鸵鸟策略、死锁检测与恢复（有向图是否有环来检测，利用抢占、回滚、kill恢复）、死锁预防（破坏四个条件）、死锁避免（判断是否是安全状态的）
    - 主要是死锁预防：破坏四个条件之一即可
      - 互斥条件不可能被破坏，因为共享资源本来就是要互斥访问的
      - 可以让线程一次性申请所有需要的资源，以破坏请求与保持条件
      - 也可以让线程在申请其他资源时，如果申请不到的话就释放自己的占有的资源，以破坏不剥夺条件
      - 可以按照一定的顺序来申请资源，释放资源则反序释放，以破坏等待条件
- 浏览器输入URL的具体过程？
  - URL解析：先判断输入的是否是合法的URL，如果合法，就判断对应的协议，如果不合法，浏览器使用搜索引擎搜索关键字
  - 查询缓存：查询浏览器中是否存在对应网页的缓存，如果有并且缓存没有过期，就直接使用缓存文件
  - DNS查询获取IP：通过DNS查询URL对应的IP地址，首先查看浏览器和操作系统中是否有对应的DNS缓存，如果没有就要向本地DNS服务器发起请求，本地DNS缓存也不存在这个域名的IP地址的话，就要进行迭代查询：根域名服务器，顶级域名服务器，权威域名服务器，
  - 建立TCP连接：获取到IP地址之后，就开始进行TCP连接了，三次握手
  - 发送HTTP请求：用已经建立的TCP连接将HTTP请求报文发送给客户端，如果是HTTPS，还需要经过SSL/TLS加密
  - 获取HTTP响应结果：服务器返回HTTP响应报文，如果是HTTPS，还需要先用密钥解密
  - 浏览器解析并且渲染页面：
    - 获取到HTML后，进行解析、渲染
  - 关闭TCP连接，或者继续保持连接
- HTTP端口、HTTPS端口？
  - HTTP：80
  - HTTP：443
- 介绍一下HTTP协议？
  - HTTP协议也叫超文本传输协议，是浏览器和服务器之间进行通信的一种规范，是基于TCP/IP协议的应用层协议
  - 为了实现浏览器和服务器的数据交互，定义了一系列的数据交互方法、包含：连接管理、缓存、状态信息、内容协商等
- GET和POST的区别？GET可以加请求体吗？那GET和POST有什么区别？不都一样的吗？
  - GET方法：获取资源的
  - POST方法：传输数据的
  - HTTP底层是TCP/IP，所以GET和POST的底层也是一样的，能够做的事情也是一样的，如果给GET加上request body，给post带上URL参数，都是可以的，HTTP只是一个协议，并不是一个实现，你可以这样干，但是我不建议你这样干，TCP才是get和post实现的基本，
    - 如果你这样干，我浏览器或者服务器承担很大的风险，因为数据量太大或者url太长会承担很大的负担，因此有的服务器会选择不处理这些请求，（一些不成文的规定）
    - (大多数）浏览器通常都会限制url长度在2K个字节，而（大多数）服务器最多处理64K大小的url。超过的部分，恕不处理。如果你用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会帮你卸货，读出数据，有些服务器直接忽略，所以，虽然GET可以带request body，也不能保证一定能被接收到哦。
  - 所以是由于HTTP的规定和浏览器服务器的限制，导致在应用过程中体现的不同
  - 区别：
    - 作用上：GET用于获取资源，向服务器索取数据的一种请求，POST用来传输实体：向服务器提交数据的请求
    - 参数上：GET的参数是出现在URL上的，URL又只支持ASCII码，所以会出现中文乱码问题，POST参数是存储在请求体中的
    - 可见性上：GET在URL上，所有人都可以看到，POST不会
    - 历史：GET的参数可以保存在浏览器历史中，POST不可以
    - 服务器安全上：GET是安全的，并不会改变服务器的状态，POST不是安全的，会改变服务器的状态
    - 在幂等性上：GET是幂等的，POST不是幂等的
    - 可缓存上：GET是可以缓存的，POST不可以缓存
    - 大小上：GET发送的数据和URL的长度相关，和具体服务器的设置有关（IIS6 2K），POST理论上没有限制
    - 产生的数据包：
      - GET浏览器会把http 的header和data一起发送出去，服务器响应200，并且返回数据
      - POST是浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 返回数据
      - 为什么要这样：
        - 因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。
        - GET和POST有自己的语言，不要混用
        - 并且在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。
        - 不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。
- Cookie和Session的区别？
  - Cookie在客户端记录信息来确定用户身份或者提供服务(检查用户的通行证)，Session通过在服务器端记录信息确定用户身份或者提供服务(服务器上的用户明细表)
  - 区别：
    - 位置上：cookie放在浏览器上，session放在服务器上
    - 生命周期上：session是浏览器启动和关闭，cookie是可以设置有效时间或者永久本地
    - 安全上：别人可以通过分析存放在本地的cookie进行cookie诈骗
    - 性能上：当访问增多，会比较占用服务器的性能，此时可以考虑使用cookie
    - 大小上：单个站点cookie在客户端的有大小限制，一般不超过3-4k
    - 保存的数据：session保存的是对象，cookie保存的字符串
    - 访问路径上：session不能区分路径，同一个浏览器在访问网站期间，所有的session在网站任何地方的可以访问到，cookie可以设置路径参数，同一个网站中的不同路径下的cookie是访问不到的
- 状态码？
  - 100：指示信息，表示请求已被接收，继续处理
  - 200：成功，表示请求已经被成功接收
  - 3xx：重定向：要完成请求必须进行更进一步的操作
  - 4xx：客户端错误
  - 5xx：服务器错误
- 线程和进程的区别？
  - 程序：包含指令和数据的文件，是静态的代码，存储在磁盘或者其他数据存储设备中
  - 进程：程序的一次执行过程，是系统运行程序的基本单位，资源分配的基本单位，是动态的，需要占用计算机的CPU、内存等资源
  - 线程：与进程类似，但是是比进程更小的执行单位，一个进程可以产生多个线程
  - 区别：
    - 从拥有的资源来看：进程是资源分配的基本单位，但是线程不拥有资源，同类线程共享进程的资源
    - 从进行的调度来看：线程是独立调度的基本单位，同一进程的线程切换不会引起进程的切换，不太消耗资源
    - 从系统开销来看：创建、撤销进程都需要系统分配或者回收资源，并且进行进程切换时，还需要进行环境保存等操作，所以说进程的开销大，而线程都是共享进程的资源，线程切换时只需要保存和设置少量的寄存器内容，开销很小
    - 从通信角度来看：线程间可以通过写同一进程中的数据进行通信，但是进程通信需要借助内核才能进行通信
- 怎么设计一个Hash表？
  - 什么是hash表，是散列表，实现字典操作的一种有效数据结构，可以通过哈希函数将关键字映射到表中的某个位置进行存放，以实现快速的插入和查询，空间换时间
  - 为什么需要哈希函数？
    - 功能：将关键字映射到M个桶中，尽可能保证均匀
    - 解决存储存储空间的问题，使每个key都能够有唯一的索引，尽可能的避免冲突，也就是尽可能的均匀
  - 采用什么样的哈希函数？以减少冲突？
    - 直接地址法：h = a*k + b
    - 除留余数法：常用
    - 随机数法
    - 数字分析法
    - 平方取中法
    - 折叠法
  - 如何处理冲突？
    - 开放定址法：也叫再散列法，出现冲突的时候，以出现冲突的hash地址为基础再散列一次，以此类推
    - 线性探测法：出现冲突时，查询下一个单元是否为空
      - 二次探测再散列法
    - 再哈希法：构造多个不同的哈希函数，每次失败都使用不同的哈希函数进行再散列
    - 拉链法：冲突后，形成链表
  - 什么时候进行扩容？
    - 负载因子：太大浪费空间，太小容易产生冲突，一般负载因子和散列函数是联动的
- 做题！
  - 时间片重复最多的个数