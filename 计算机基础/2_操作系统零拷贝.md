# 操作系统-零拷贝理解

- 主要参考自：
  - https://blog.csdn.net/Youth_lql/article/details/115524139?spm=1001.2014.3001.5501
- 最好先理解：操作系统的IO模型，也就是上一部分！
  - 用户空间、内核空间、IO模型
- 阅读本节后，最好需要理解：
  - 计算机为了尽可能的不让CPU休息、充分发挥CPU的计算能力所做的努力！
  - 因为需要等待其他操作产生的耗时=》不要轮询，引入中断=》进而可以多进程并发
  - 因为需要等待磁盘数据加载到内存(内核空间)中=》之前CPU实现，现在CPU和磁盘控制器中加了一层：DMA，让DMA去完成磁盘数据到内存的读取过程
  - 因为IO过程的最耗时操作是用户线程需要等待CPU将内核空间数据拷贝到用户空间才可以让用户线程进行操作
    - =》系统调用：mmap()使用内存指针来代替内核空间数据拷贝到用户空间，在真正需要操作该内存数据时，再从内核空间中加载读取
    - =》系统调用：sendfile()：数据不经过用户空间，CPU直接从内核空间拷贝到socket缓存区
    - =》系统调用：sendfile()优化：数据不经过用户空间，DMA直接从内核空间拷贝到协议栈

# 1.前置知识

- 计算机系统架构图：
- ![image-20211119112916286](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119112916286.png)

## 1.1 标准设备

- 什么是标准设备？
  - CPU使用设备的标准设备模型，给定的一种协议、规范！
  - ![image-20211119112843011](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119112843011.png)
  - 不是真实存在的，相当于一个逻辑上抽象的东西，一种协议、规范
    - 通过它来帮助我们更好地理解设备交互的机制
  - 第一部分是向系统其他部分展现的硬件接口（interface）。同软件一样，硬件也需要一些接口，让系统软件来控制它的操作。因此，所有设备都有自己的特定接口以及典型交互的协议。
  - 第二部分是它的内部结构（internal structure）。这部分包含设备相关的特定实现，负责具体实现设备展示给系统的抽象接口。非常简单的设备通常用一个或几个芯片来实现它们的功能。更复杂的设备(RAID，廉价冗余磁盘阵列)会包含简单的 CPU、一些通用内存、设备相关的特定芯片，来完成它们的工作。

## 1.2 标准协议

- 什么是标准协议？
  
  - CPU使用设备的标准使用协议，给定的一种协议、规范！
  
  - 根据上图，我们可以得知：
  
  - 标准设备中包含3个寄存器：
    
    1. 状态(status)寄存器， 可以读取并查看设备的当前状态。
    2. 命令(command)寄存器，用于通知设备执行某个具体任务
    3. 数据(data)寄存器，将数据传给设备或从设备接收数据。
  
  - 通过读写这些寄存器，操作系统可以控制设备的行为。
    
    - 假设操作系统与标准设备交互的标准协议如下：
    
    - ```c
      While (STATUS == BUSY);//wait until device is not busy
      
      Write data to DATA register
      Write command to COMMAND register
          (Doing so starts the device and executes the command)
      
      While (STATUS == BUSY);//wait until device is done with your request
      ```
  
  - 该协议包含4步。
    
    - 第1步，操作系统通过反复读取状态寄存器，等待设备进入可以接收命令的就绪状态。我们称之为轮询（polling）设备（基本上，就是问它正在做什么）。
    - 第2步，操作系统下发数据到数据寄存器。例如，你可以想象如果这是一个磁盘，需要多次写入操作，将一个磁盘块（比如4KB）传递给设备。如果主CPU参与数据移动（就像这个示例协议一样），我们就称之为编程的I/O（programmedI/O，PIO）。
    - 第3步，操作系统将命令写入命令寄存器；这样设备就知道数据已经准备好了，它应该开始执行命令。
    - 第4步，操作系统再次通过不断轮询设备，等待并判断设备是否执行完成命令（有可能得到一个指示成功或失败的错误码）。

- 计算机的设备一般都遵循这些标准设备、标准协议的规范设计的，但是存在一些问题？
  
  - 如何减少轮询开销？
  - 操作系统检查设备状态时如何避免频繁轮询？
  - 如何降低管理设备的CPU开销？

## 1.3 中断-减少CPU开销

- 什么是中断？
  - CPU对系统发生的某个事件做出的一种反应，CPU暂停正在执行的程序，保存现场后自动去执行相应的处理程序，处理完该事件后再返回中断处继续执行原来的程序。
- 中断的类别？
  - 一种是由CPU外部引起的，称为**外中断**。如I/O中断、时钟中断，
  - 一种是来自CPU内部事件或程序执行中引起的中断，例如程序非法操作，地址越界、浮点溢出）称为**内中断**，或者（异常，陷入），
  - 最后一种是在程序中使用了系统调用引起的。而**中断处理**一般分为中断响应和中断处理两个步骤，中断响应由硬件实施，中断处理主要由软件实施。
- 有了中断后，CPU 不再需要不断轮询设备，而是向设备发出一个请求，然后就可以让对应进程睡眠，切换执行其他任务。当设备完成了自身操作，会抛出一个硬件中断，引发CPU跳转执行操作系统预先定义好的中断服务例（InterruptService Routine，ISR），或更为简单的中断处理程序（interrupt handler）。中断处理程序是一小段操作系统代码，它会结束之前的请求（比如从设备读取到了数据或者错误码）并且唤醒等待I/O的进程继续执行。
- 示例：
  - 没有中断时：进程1在CPU上运行一段时间（对应CPU那一行上重复的1），然后发出一个读取数据的I/O请求给磁盘。如果没有中断，那么操作系统就会简单自旋，不断轮询设备状态，直到设备完成I/O操作（对应其中的p）。当设备完成请求的操作后，进程1又可以继续运行。
    - ![image-20211119114134227](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119114134227.png)
  - 有了中断后：中断允许计算与I/O重叠（overlap），这是提高CPU利用率的关键。在磁盘处理进程 1 的请求时，操作系统在 CPU 上运行进程 2。磁盘处理完成后，触发一个中断，然后操作系统唤醒进程 1 继续运行。这样，在这段时间，无论 CPU 还是磁盘都可以有效地利用。
    - ![image-20211119114226809](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119114226809.png)
- 存在的问题：
  - 假如有一个非常高性能的设备，它处理请求很快：通常在CPU第一次轮询时就可以返回结果。此时如果使用中断，反而会使系统变慢：切换到其他进程，处理中断，再切换回之前的进程代价不小。
  - 如果设备非常快，那么最好的办法反而是轮询。
  - 如果设备比较慢，那么采用允许发生重叠的中断更好。
  - 如果设备的速度未知，或者时快时慢，可以考虑使用混合（hybrid）策略，先尝试轮询一小段时间，如果设备没有完成操作，此时再使用中断。这种两阶段（two-phased）的办法可以实现两种方法的好处。
- IO过程简述：
  - ![image-20211119114522787](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119114522787.png)
  - 1、用户进程调用read方法，想cpu发送IO请求，用户态转换为内核态
  - 2、CPU向磁盘发起IO请求给磁盘控制器，**之后立马返回**，返回后的CPU可以切换到其他进程执行其他操作（或者继续执行用户进程的其他操作）
  - 3、磁盘控制器收到指令后，开始进行磁盘IO，磁盘IO完成后会把数据放到磁盘控制器的内部缓存区中，并且发起一个中断（外中断）
  - 4、CPU收到中断信号后，停止目前的工作(上下文切换，**此时用户线程阻塞挂起**)，把磁盘控制器中的缓冲区数据读取到内核的页缓存中（**该过程可以使用DMA进行优化，待续**）
  - 5、将给数据从内核页缓存拷贝到用户进程空间（**此时用户线程都是在阻塞挂起状态，等待CPU完成拷贝后，继续使用CPU**）（**此过程可以使用异步IO优化**）
  - 6、最后read调用返回
- 所以：使用中断减少CPU开销时，在进行磁盘IO期间，CPU可以执行其他的进程不必等待磁盘IO。

## 1.4 DMA-优化数据存取

- 之前存在的问题：
  - 需要CPU来调度实现磁盘控制器的缓冲区数据读取到页缓存中！
  - 浪费CPU资源！
- 什么是DMA？
  - Direct Memory Access：可以协调完成内存和设备间的数据传递，不需要 CPU 介入。
  - 为了能够将数据传送给设备，操作系统会通过编程告诉 DMA 引擎数据在内存的位置，要拷贝的大小以及要拷贝到哪个设备。在此之后，操作系统就可以处理其他请求了。当 DMA 的任务完成后，DMA 控制器会抛出一个中断来告诉操作系统自己已经完成数据传输。
- 示例：
  - 不使用DMA的一般情况：进程 1 在运行过程中需要向磁盘写一些数据，所以它开始进行 I/O 操作，将数据从内存 拷贝到磁盘(其中标示 c 的过程)。拷贝结束后，磁盘上的 I/O 操作开始执行，此时 CPU 才 可以处理其他请求。
    - ![image-20211119120146288](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119120146288.png)
  - 使用DMA：数据的拷贝工作都是由 DMA 控制器来完成的。因为 CPU 在此时是空闲的，所以操作系统可以让它做一些其他事情，比如此处调度进程 2 到 CPU 来运行。 因此进程 2 在进程 1 再次运行之前可以使用更多的 CPU。
    - ![image-20211119120219307](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119120219307.png)
- 使用了DMA的IO过程简述：
  - ![image-20211119120339407](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119120339407.png)
  - 1、用户进程调用 read 方法，向cpu发出 I/O 请求
  - 2、cpu将IO请求交给DMA控制器，之后自己立马返回去执行其他进程的任务
  - 3、DMA向磁盘发起IO请求
  - 4、磁盘控制器收到指令后，于是就开始进行磁盘IO，磁盘IO完成后会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断。
  - 5、DMA收到中断后，把磁盘控制器的缓冲区的数据读进内核的页缓存，接着抛出一个中断
  - 6、操作系统收到中断后，调度cpu回来执行之前的进程：将数据从内核页缓存拷贝到用户进程空间【这一步还是只能用异步IO来优化】
  - 7、最后read()调用返回。

# 2. 零拷贝

## 2.1 传统文件IO

- 场景：将服务器中的磁盘上的文件读取出来，然后通过网络协议发送给客户端。
- ![image-20211119120938678](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119120938678.png)
- 很明显发生了4次拷贝
  - 第一次拷贝：DMA完成：把磁盘上的数据拷贝到操作系统内核的缓冲区里
  - 第二次拷贝：CPU完成：把内核缓冲区的数据拷贝到用户的缓冲区里，于是应用程序就可以使用这部分数据了，这个拷贝是由 CPU 完成的。
  - 第三次拷贝：CPU完成：把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然由 CPU 完成的。
  - 第四次拷贝：DMA完成：把内核的 socket 缓冲区里的数据，拷贝到协议栈里
- 发生了两个系统调用read和write=》一个系统调用对应两次上下文切换，所以上下文切换次数在一般情况下只可能是偶数。
- 因此一共发生了4次用户上下文切换
- 存在的问题：
  - 上下文切换、CPU数据拷贝耗费的时间很大！
  - 因此要从这两个方向改进！

## 2.2 mmap()

- 什么是mmap()？
  - 也是一种系统调用(用于操作计算机内核的函数！)
  - 功能：存储映射使一个磁盘文件映射到内存中，可以在不使用read、write的情况下，使用指针完成IO操作。可以将文件的一段映射到内存中。实际使用时，使用页面置换算法把要使用的数据给读取出来！
  - ![image-20211119121632382](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119121632382.png)
- 场景：将服务器中的磁盘上的文件读取出来，然后通过网络协议发送给客户端。
  - read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。mmap() 系统调用函数会直接把内核缓冲区里的数据映射到用户空间，这样，操作系统内核与用户空间共享缓冲区，就不需要再进行任何的数据拷贝操作。
  - ![image-20211119121809115](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119121809115.png)
  - 总的来说mmap减少了一次数据拷贝，总共4次上下文切换，3次数据拷贝

## 2.3 sendfile()

- 什么是sendfile()？
  - `Linux2.1` 版本提供了 `sendFile` 函数，其基本原理如下：数据根本不经过用户态，直接从内核缓冲区进入到 `SocketBuffer`
- 场景：将服务器中的磁盘上的文件读取出来，然后通过网络协议发送给客户端。
  - ![image-20211119122045138](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119122045138.png)
  - 总的来说有2次上下文切换，3次数据拷贝。

## 2.4 sendfile()再优化=>零拷贝

- `Linux在2.4` 版本中，做了一些修改，避免了从内核缓冲区拷贝到 `Socketbuffer` 的操作，直接拷贝到协议栈，从而再一次减少了数据拷贝
- 场景：将服务器中的磁盘上的文件读取出来，然后通过网络协议发送给客户端。
  - ![image-20211119122142861](2_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9B%B6%E6%8B%B7%E8%B4%9D.assets/image-20211119122142861.png)
- 此时只有2次上下文切换、2次数据拷贝
  - 并且此时不需要CPU进行内核缓存区的拷贝，全部交给DMA完成！实现零拷贝

# 3.总结文件传输

- 已经了解了操作系统的基本IO模型，改进过程和计算机内部的数据传输过程(零拷贝)等，此时做一个简单的文件传输总结
- **小文件传输**
  - 前文一直提到了内核里的页缓存(PageCache)，这个页缓存的作用就是用来提升小文件传输的效率
  - 原因：
    - 读写磁盘相比读写内存的速度慢太多了，这个有点基础的人应该都知道，所以我们应该想办法把读写磁盘换成读写内存。于是，我们通过 DMA 把磁盘里的数据拷贝到内存里，这样就可以用读内存替换读磁盘。读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。这点不是很类似redis和mysql的关系吗，所以说操作系统里的一些设计理念和平时工作应用息息相关，毕竟操作系统可是无数大牛的结晶
    - 程序运行的时候，具有局部性原理，也就是说刚被访问的数据在短时间内再次被访问的概率很高，通常称为热点数据，于是我们用 PageCache 来缓存这些热点数据，当空间不足时有对应的缓存淘汰策略。
- **大文件传输：**
  - PageCache可以用来大文件传输吗？
  - 不能
  - 为什么呢？
  - 假设你要几G的数据要传输，用户访问这些大文件的时候，内核会把它们载入 PageCache 中， PageCache 空间很快被这些大文件占满。
  - PageCache 由于长时间被大文件占据，其他热点小文件可能就无法使用到 PageCache，就频繁读写磁盘，效率低下
  - 而PageCache 中的大文件数据，没有享受到缓存带来的好处，反而却耗费 DMA 多拷贝到 PageCache 一次
  - 这前前后后加起来，效率低了很多，所以PageCache不适合大文件传输
- 而想不用到内核缓冲区，我们就想到了**直接IO**这个东西，直接IO不经过内核缓存，同时经过上面的讲述，我们也可以知道异步IO效率是最高的。所以大文件传输最好的解决办法应该是：**异步IO+直接IO**